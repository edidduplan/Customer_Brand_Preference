---
title: "Brand Preference Prediction Report"
author: "Edison Guevara"
date: "14/10/2019"
output: 
    prettydoc::html_pretty:
    theme: cayman
    highlight: github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = T, warning = F, message = F)
```

# Goal and Objectives

In order for the Sales Teams to decide with which brand of computers (Acer or Sony) to persue a deeper strategic relationship, a market research firm has been engaged to conduct a survey on our existing customers.
One of the objectives of the survey is to identify computer's brand preferences among the customers.
A model is to be developed and tested in order to predict the customer's brand preference based on other demographis data of an incomplete survey. This will allow us at the same time to extrapolate the results of the survey to all the customers and persue specific marketing strategies.

# Excecutive Summary

# Data 

The data used to develop the model contains around 10.000 survey of customer's brand preference including other demographic features:

- Salary (yearly)
- Age
- Educational level
- Make of primary car
- Zipcode
- Credit available
- Computers' brand preference (Acer/Sony)

# Pre-processing the data

The data has been first reviewd and the attributes type have been changed to be suited for the analysis.

```{r, echo = FALSE}
# Loading reguired libraries
pacman::p_load(caret, tidyverse, readr, party, ggthemes, plotly, shiny, C50)
pacman::p_load(C50)
library(party)
library(party)
library(C50)
# Setting working directory
setwd("C:/Users/edison/Documents/Ubiqum/Data Analytics Course/Module II/Task2_revisited/")

```

```{r, echo=FALSE}
# Import data

CompleteResponses <- read.csv(file="Data/CompleteResponses.csv", header=TRUE, sep=";")

SurveyIncomplete <- read.csv(file="Data/SurveyIncomplete.csv", header=TRUE, sep=",")


# Changing attributes type
CompleteResponses$age <- as.integer(CompleteResponses$age)
CompleteResponses$elevel <- as.ordered(CompleteResponses$elevel)
CompleteResponses$car <- as.factor(CompleteResponses$car)
CompleteResponses$zipcode <- as.factor(CompleteResponses$zipcode)
CompleteResponses$brand <- as.character(CompleteResponses$brand)

# Changing names of levels in brand
CompleteResponses[which(CompleteResponses$brand == 0), 
                  "brand"] <- "Acer"
CompleteResponses[which(CompleteResponses$brand == 1), 
                  "brand"] <- "Sony"

CompleteResponses$brand <- as.factor(CompleteResponses$brand)

SurveyIncomplete$salary <- as.numeric(SurveyIncomplete$salary)
SurveyIncomplete$age <- as.integer(SurveyIncomplete$age)
SurveyIncomplete$elevel <- as.ordered(SurveyIncomplete$elevel)
SurveyIncomplete$car <- as.factor(SurveyIncomplete$car)
SurveyIncomplete$zipcode <- as.factor(SurveyIncomplete$zipcode)
SurveyIncomplete$credit <- as.numeric(SurveyIncomplete$credit)

```

# Exploring the Data

## Histograms
The distribution of the data has been studied using histograms. Below it can be seen different histograms for the original data, as well as histograms for the incomplete survey data. In this way we can compare the distribution among both samples (i.e. original data and incomplete data). The histograms have been segregated by brand, in order to look for associations at the same time.


```{r, echo=F}
# Histograms
# Hist salary
ggplot(CompleteResponses, aes(x = salary, fill = brand)) + 
  geom_histogram(binwidth = 10000, 
                 color = "white") + 
  ggtitle("Histogram CompleteResponse - Salary")
#  scale_fill_manual(values = c("grey", "black")) + 
#  facet_grid(elevel ~ zipcode, labeller = label_both) +
#  facet_grid(. ~ elevel, labeller = label_both)

ggplot(SurveyIncomplete, aes(x = salary)) + 
  geom_histogram(binwidth = 10000, 
                 color = "white") + 
  ggtitle("Histogram SurveyIncomplete - Salary")

```

The overall distribution of salary is similar in both data sets. This is very important in order to have a reliable model. 
On the other hand, it can be seen that the distribution of salary for Acer fans is different to the one of Sony fans. This revelas some dependancy between salary and brand preference.

```{r, echo=FALSE}
# Hist age
ggplot(CompleteResponses, aes(x = age, fill = brand)) + 
  geom_histogram(binwidth = 5, color = "white" ) + 
  ggtitle("Histogram CompleteResponse - age")
ggplot(SurveyIncomplete, aes(x = age)) + 
  geom_histogram(binwidth = 5, color = "white") + 
  ggtitle("Histogram SurveyIncomplete - age")
```

The overall distribution of age is also very similar among both datasets.
Unlike while looking at salary, in the case of age there is not clear association between the latest and the brand.

```{r, echo = F}
# Hist elevel
CompleteResponses$elevel <- as.integer(CompleteResponses$elevel)
SurveyIncomplete$elevel <- as.integer(SurveyIncomplete$elevel)

ggplot(CompleteResponses, aes(x = elevel, fill = brand)) + 
  geom_histogram(binwidth = 1, color = "white") + 
  ggtitle("Histogram CompleteResponse - education level")

ggplot(SurveyIncomplete, aes(x = elevel)) + 
  geom_histogram(binwidth = 1, color = "white") + 
  ggtitle("Histogram SurveyIncomplete - education level")

CompleteResponses$elevel <- as.ordered(CompleteResponses$elevel)
SurveyIncomplete$elevel <- as.ordered(SurveyIncomplete$elevel)
```

Key:

- 0	Less than High School Degree
- 1	High School Degree
- 2	Some College
- 3	4-Year College Degree
- 4	Master's, Doctoral or Professional Degree


```{r, echo=F}
# Hist car
CompleteResponses$car <- as.integer(CompleteResponses$car)
SurveyIncomplete$car <- as.integer(SurveyIncomplete$car)

ggplot(CompleteResponses, aes(x = car, fill = brand)) + 
  geom_histogram(binwidth = 1, color = "white") + 
  ggtitle("Histogram CompleteResponse - car")
ggplot(SurveyIncomplete, aes(x = car)) + 
  geom_histogram(binwidth = 1, color = "white") + 
  ggtitle("Histogram SurveyIncomplete - car")

CompleteResponses$car <- as.factor(CompleteResponses$car)
SurveyIncomplete$car <- as.factor(SurveyIncomplete$car)
```

Key:

- 1	BMW
- 2	Buick
- 3	Cadillac
- 4	Chevrolet
- 5	Chrysler
- 6	Dodge
- 7	Ford
- 8	Honda
- 9	Hyundai
- 10	Jeep
- 11	Kia
- 12	Lincoln
- 13	Mazda
- 14	Mercedes Benz
- 15	Mitsubishi
- 16	Nissan
- 17	Ram
- 18	Subaru
- 19	Toyota
- 20	None of the above


```{r, echo=F}
# Hist zipcode
CompleteResponses$zipcode <- as.integer(CompleteResponses$zipcode)
SurveyIncomplete$zipcode <- as.integer(SurveyIncomplete$zipcode)

ggplot(CompleteResponses, aes(x = zipcode, fill = brand)) + 
  geom_histogram(binwidth = 1, color = "white") + 
  ggtitle("Histogram CompleteResponse - zipcode")

ggplot(SurveyIncomplete, aes(x = zipcode)) + 
  geom_histogram(binwidth = 1, color = "white") + 
  ggtitle("Histogram SurveyIncomplete - zipcode")

CompleteResponses$zipcode <- as.factor(CompleteResponses$zipcode)
SurveyIncomplete$zipcode <- as.factor(SurveyIncomplete$zipcode)
```

0	New England
1	Mid-Atlantic
2	East North Central
3	West North Central
4	South Atlantic
5	East South Central
6	West South Central
7	Mountain
8	Pacific

```{r, echo=F}
# Hist credit
ggplot(CompleteResponses, aes(x = credit, fill = brand)) + 
  geom_histogram(binwidth = 50000, color = "white") + 
  ggtitle("Histogram CompleteResponse - credit")
ggplot(SurveyIncomplete, aes(x = credit)) + 
  geom_histogram(binwidth = 50000, color = "white") + 
  ggtitle("Histogram SurveyIncomplete - credit")

```

The distributions of education level, car, zipcode and credit are pretty similar in both datasets. As explained before, this is very important in order to have a reliable model.

## Scatter plots

In order to explore deeper the relationship between the different attributes and brand, scatter plots have been made.

```{r, echo=F}
ggplot(CompleteResponses, aes(x = age, y = salary, color = brand)) +
  geom_point() + geom_smooth()

```

```{r, echo=F}
ggplot(CompleteResponses, aes(x = elevel, y = salary, color = brand)) + geom_point(position = "jitter")

```

As can be seen in plot salary vs age, there is also a dependancy of brand towards attribute age. 
On the other hand, there seems not to be any association with education level and brand.

## Looking for outliers

Boxplots for the numerical attributes (salary and credit) have been obtained. As can be seen there are no outliers in either one variable.

```{r, echo=F}
ggplot(CompleteResponses, aes(x = brand, y = salary, 
                              fill = brand)) + 
  geom_boxplot() + 
  stat_summary(fun.y = median, color = "white", geom = "text",
               vjust = -0.7, 
               aes(label = round(..y.., digits = 1)))
```

```{r, echo=F}
ggplot(CompleteResponses, aes(x = brand, y = credit, 
                              fill = brand)) + 
  geom_boxplot() + 
  stat_summary(fun.y = median, color = "white", geom = "text",
               vjust = -0.7, 
               aes(label = round(..y.., digits = 1)))
```

# Feature selection

```{r, echo=F}
set.seed(123)
DecisionTree_brand <- ctree(brand ~ ., data = CompleteResponses, controls = ctree_control(maxdepth = 3))
plot(DecisionTree_brand)
```

# Modeling

Two different decision tree classification methods have been included: C5.0 and RandomForest.

##  Creating training and testing sets

In order to train and test the models, the original data (complete data) has been split into a training and a test set. The proportion used is 0.75 to 0.25.

```{r}
trainSize <- createDataPartition(y=CompleteResponses$brand, p = .75, list = F)
trainSet <- CompleteResponses[trainSize,]
testSet <- CompleteResponses[-trainSize,]
```

## C5.0

### Training the model

The C5.0 model has been trained using cross-validation 10 folds, 3 repetitions, as resampling method.
Below it can be seen the results using automatic tuning with tunelength = 2.

```{r, echo=F}
ctrl <- trainControl(method = "repeatedcv", 
                     repeats = 3,
                     classProbs = T,
                     summaryFunction = twoClassSummary)

# Automatic tunning
modelo_c50_auto <- train(brand ~ ., 
                data = trainSet, 
                method = "C5.0",
                tuneLength = 2,
                trControl = ctrl,
                metric = "ROC",
                preProc = c("center", "scale"))
```

```{r}
modelo_c50_auto
```

ROC has been used as a criterium to select the best model since ours is a 2 class problem. ROC gives an indication of hoe well the clasification has resulted. The closer to 1 the value of ROC, the best clasified are the classes.

### Testing the model

After training the C5.0 model on the training set, its performance has been tested on the test set.
Below the confusion matrix for the test set can be appreciated. An accuracy of 0.9276 and a kappa of 0.8486 speak for a very good prediction.

```{r}
predict_c50_auto_classes <- predict(modelo_c50_auto, newdata = testSet)
predict_c50_auto_prob <- predict(modelo_c50_auto, newdata = testSet, type = "prob")
confusionMatrix(data = predict_c50_auto_classes, testSet$brand)
```

## Random Forest

### Training the model

```{r}
rf_ctrl <- trainControl(method = "repeatedcv", 
                     repeats = 1,
                     classProbs = T,
                     summaryFunction = twoClassSummary)

rf_grid <- expand.grid(mtry=c(1,2,3))

system.time(modelo_rf_man <- train(brand ~ ., 
                                   data = trainSet, 
                                   method = "rf", 
                                   trControl = rf_ctrl, 
                                   tuneGrid= rf_grid,
                                   metric = "ROC",
                                   preProc = c("center", "scale")))

```

## Testing the model

```{r}
predict_rf_man_classes <- predict(modelo_rf_man, newdata = testSet)
head(predict_rf_man_classes)
confusionMatrix(data = predict_c50_auto_classes, testSet$brand)
```

## Selecting the model

```{r, echo=F}
# resamps <- resamples(list( C50= modelo_c50_auto, rf =                              modelo_rf_man))
# summary(resamps)

```

```{r}
predict2 <- predict(modelo_c50_auto, newdata = SurveyIncomplete)
SurveyIncomplete$brand <- predict2_c50_auto_classes
```


# Next Steps
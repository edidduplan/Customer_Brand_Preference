---
title: "Brand Preference Prediction Report"
author: "Edison Guevara"
date: "14/10/2019"
output: 
  md_document:
    variant: markdown_github
#    prettydoc::html_pretty:
#    theme: cayman
#    highlight: github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = T, warning = F, message = F)
```

# Goal and Objectives

In order for the Sales Teams to decide with which brand of computers (Acer or Sony) to persue a deeper strategic relationship, a market research firm has been engaged to conduct a survey on Blackwell's existing customers.

One of the objectives of the survey is to identify computer's brand preferences among the customers.

A model is to be developed and tested in order to predict the customer's brand preference based on other demographis data of an incomplete survey. This will allow us at the same time to extrapolate the results of the survey to all the customers and persue specific marketing strategies.

# Excecutive Summary

The results of this report are not conclusive as to persue a strategic partnership with Sony or Acer.

An additional survey following a random sampling strategy is needed in order to estimate the population distribution of age and salary. In this way, the market shares of Acer and Sony can be better assessed.

However, a model has been built on the available data and the brand preference has been predicted on the incomplete survey. The share of brands is (as expected) again around 60/40 being Sony the most popular. However, this result should be validated following a random sampling survey.

# Data 

The data used to develop the model contains around 10.000 survey of customer's brand preference including other demographic features:

- Salary (yearly)
- Age
- Educational level
- Make of primary car
- Zipcode
- Credit available
- Computers' brand preference (Acer/Sony)

# Pre-processing the data

The data has been first reviewd and the attributes type have been changed to be suited for the analysis.

```{r, echo = FALSE}
# Loading reguired libraries
pacman::p_load(caret, tidyverse, readr, party, ggthemes, plotly, shiny, C50)
pacman::p_load(C50)
library(party)
library(party)
library(C50)
# Setting working directory
setwd("C:/Users/edidd/Documents/Ubiqum/Data Analytics Course/Module II/Task2_revisited/")

```

```{r, echo=FALSE}
# Import data

CompleteResponses <- read.csv(file="Data/CompleteResponses.csv", header=TRUE, sep=";")

SurveyIncomplete <- read.csv(file="Data/SurveyIncomplete.csv", header=TRUE, sep=",")


# Changing attributes type
CompleteResponses$age <- as.integer(CompleteResponses$age)
CompleteResponses$elevel <- as.ordered(CompleteResponses$elevel)
CompleteResponses$car <- as.factor(CompleteResponses$car)
CompleteResponses$zipcode <- as.factor(CompleteResponses$zipcode)
CompleteResponses$brand <- as.character(CompleteResponses$brand)

# Changing names of levels in brand
CompleteResponses[which(CompleteResponses$brand == 0), 
                  "brand"] <- "Acer"
CompleteResponses[which(CompleteResponses$brand == 1), 
                  "brand"] <- "Sony"

# CompleteResponses[CompleteResponses$brand == 1,] <- "test"

CompleteResponses$brand <- as.factor(CompleteResponses$brand)

SurveyIncomplete$salary <- as.numeric(SurveyIncomplete$salary)
SurveyIncomplete$age <- as.integer(SurveyIncomplete$age)
SurveyIncomplete$elevel <- as.ordered(SurveyIncomplete$elevel)
SurveyIncomplete$car <- as.factor(SurveyIncomplete$car)
SurveyIncomplete$zipcode <- as.factor(SurveyIncomplete$zipcode)
SurveyIncomplete$credit <- as.numeric(SurveyIncomplete$credit)
SurveyIncomplete$brand <- as.factor(SurveyIncomplete$brand)

```

# Exploring the Data

Below the summary of the complete survey is shown:

```{r}
summary(CompleteResponses)
```


## Histograms
The distribution of the data has been studied using histograms. Below it can be seen different histograms for the original data, as well as histograms for the incomplete survey data. In this way we can compare the distribution among both samples (i.e. original data and incomplete data). The histograms have been segregated by brand, in order to look for associations at the same time.


```{r, echo=F}
# Histograms
# Hist salary
ggplot(CompleteResponses, aes(x = salary, fill = brand)) + 
  geom_histogram(binwidth = 10000, 
                 color = "white") + 
  ggtitle("Histogram CompleteResponse - Salary")
#  scale_fill_manual(values = c("grey", "black")) + 
#  facet_grid(elevel ~ zipcode, labeller = label_both) +
#  facet_grid(. ~ elevel, labeller = label_both)

ggplot(SurveyIncomplete, aes(x = salary)) + 
  geom_histogram(binwidth = 10000, 
                 color = "white") + 
  ggtitle("Histogram SurveyIncomplete - Salary")

```

The overall distribution of salary is similar in both data sets. This is very important in order to have a reliable model. 
On the other hand, it can be seen that the distribution of salary for Acer fans is different to the one of Sony fans. This revelas some dependancy between salary and brand preference.

```{r, echo=FALSE}
# Hist age
ggplot(CompleteResponses, aes(x = age, fill = brand)) + 
  geom_histogram(binwidth = 5, color = "white" ) + 
  ggtitle("Histogram CompleteResponse - age")
ggplot(SurveyIncomplete, aes(x = age)) + 
  geom_histogram(binwidth = 5, color = "white") + 
  ggtitle("Histogram SurveyIncomplete - age")
```

The overall distribution of age is also very similar among both datasets.
Unlike while looking at salary, in the case of age there is not clear association between the latest and the brand.

```{r, echo = F}
# Hist elevel
str(CompleteResponses)
ggplot(CompleteResponses, aes(x = as.integer(elevel), fill = brand)) + 
  geom_histogram(binwidth = 1, color = "white") + 
  ggtitle("Histogram CompleteResponse - education level")

ggplot(SurveyIncomplete, aes(x = as.integer(elevel))) + 
  geom_histogram(binwidth = 1, color = "white") + 
  ggtitle("Histogram SurveyIncomplete - education level")

```

Key:

- 0	Less than High School Degree
- 1	High School Degree
- 2	Some College
- 3	4-Year College Degree
- 4	Master's, Doctoral or Professional Degree


```{r, echo=F}
# Hist car
CompleteResponses$car <- as.integer(CompleteResponses$car)
SurveyIncomplete$car <- as.integer(SurveyIncomplete$car)

ggplot(CompleteResponses, aes(x = car, fill = brand)) + 
  geom_histogram(binwidth = 1, color = "white") + 
  ggtitle("Histogram CompleteResponse - car")
ggplot(SurveyIncomplete, aes(x = car)) + 
  geom_histogram(binwidth = 1, color = "white") + 
  ggtitle("Histogram SurveyIncomplete - car")

CompleteResponses$car <- as.factor(CompleteResponses$car)
SurveyIncomplete$car <- as.factor(SurveyIncomplete$car)
```

Key:

- 1	BMW
- 2	Buick
- 3	Cadillac
- 4	Chevrolet
- 5	Chrysler
- 6	Dodge
- 7	Ford
- 8	Honda
- 9	Hyundai
- 10	Jeep
- 11	Kia
- 12	Lincoln
- 13	Mazda
- 14	Mercedes Benz
- 15	Mitsubishi
- 16	Nissan
- 17	Ram
- 18	Subaru
- 19	Toyota
- 20	None of the above


```{r, echo=F}
# Hist zipcode
CompleteResponses$zipcode <- as.integer(CompleteResponses$zipcode)
SurveyIncomplete$zipcode <- as.integer(SurveyIncomplete$zipcode)

ggplot(CompleteResponses, aes(x = zipcode, fill = brand)) + 
  geom_histogram(binwidth = 1, color = "white") + 
  ggtitle("Histogram CompleteResponse - zipcode")

ggplot(SurveyIncomplete, aes(x = as.factor(zipcode))) + 
  geom_bar(binwith = 1, color = "white") + 
  ggtitle("Histogram SurveyIncomplete - zipcode") + 
  scale_x_discrete(breaks = c(0, 1, 2, 3, 4, 5, 6, 7, 8), labels = c("a", "b", "c", "d", "e", "f", "g", "h", "i"))

CompleteResponses$zipcode <- as.factor(CompleteResponses$zipcode)
SurveyIncomplete$zipcode <- as.factor(SurveyIncomplete$zipcode)
```

0	New England
1	Mid-Atlantic
2	East North Central
3	West North Central
4	South Atlantic
5	East South Central
6	West South Central
7	Mountain
8	Pacific

```{r, echo=F}
str(CompleteResponses)

# Hist credit
ggplot(CompleteResponses, aes(x = credit, fill = brand)) + 
  geom_histogram(binwidth = 50000, color = "white") + 
  ggtitle("Histogram CompleteResponse - credit")
ggplot(SurveyIncomplete, aes(x = credit)) + 
  geom_histogram(binwidth = 50000, color = "white") + 
  ggtitle("Histogram SurveyIncomplete - credit")

```

The distributions of education level, car, zipcode and credit are pretty similar in both datasets. As explained before, this is very important in order to have a reliable model.

## Scatter plots

In order to explore deeper the relationship between the different attributes and brand, scatter plots have been made.

```{r, echo=F}
ggplot(CompleteResponses, aes(x = age, y = salary, color = brand)) +
  geom_point() + geom_smooth()

```

```{r, echo=F}
ggplot(CompleteResponses, aes(x = elevel, y = salary, color = brand)) + geom_point(position = "jitter")

```

As can be seen in plot salary vs age, there is also a dependancy of brand towards attribute age. 
On the other hand, there seems not to be any association with education level and brand.

## Looking for outliers

Boxplots for the numerical attributes (salary and credit) have been obtained. As can be seen there are no outliers in either one variable.

```{r, echo=F}
ggplot(CompleteResponses, aes(x = brand, y = salary, 
                              fill = brand)) + 
  geom_boxplot() + 
  stat_summary(fun.y = median, color = "white", geom = "text",
               vjust = -0.7, 
               aes(label = round(..y.., digits = 1)))
```

```{r, echo=F}
ggplot(CompleteResponses, aes(x = brand, y = credit, 
                              fill = brand)) + 
  geom_boxplot() + 
  stat_summary(fun.y = median, color = "white", geom = "text",
               vjust = -0.7, 
               aes(label = round(..y.., digits = 1)))
```

# Feature selection

A single Decision Tree has been obtained in order to select the attributes which have an association to the investigated veriable, brand.

As can be seen in the Decision Tree below, only salary and age play a considerable role.

However, all attributes will be used for the development of the models, since both models used in this study are decision-tree-based and the unimportant attributes will be anyways discarded.

```{r, echo=F}
set.seed(123)
DecisionTree_brand <- ctree(brand ~ ., data = CompleteResponses, controls = ctree_control(maxdepth = 3))
plot(DecisionTree_brand)
```

# Modeling

Two different decision tree classification methods have been included: C5.0 and RandomForest.

##  Creating training and testing sets

In order to train and test the models, the original data (complete survey) has been split into a training and a test set. The proportion used is 0.75 to 0.25.

```{r}
trainSize <- createDataPartition(y=CompleteResponses$brand, p = .75, list = F)
trainSet <- CompleteResponses[trainSize,]
testSet <- CompleteResponses[-trainSize,]
```

## C5.0

### Hyperparameter selection with cross-validation (automatic tunning)

Hyperparameter selection has been done with R package caret using automatic tunning with tunelength = 3. For the validation of models (hyperparameters) the data has been resampled using cross-validation 10 folds.
The cross-validation results for the tunning parameters can bee seen below:

```{r, echo=F}
ctrl <- trainControl(method = "repeatedcv", 
                     repeats = 1,
                     classProbs = T,
                     summaryFunction = twoClassSummary)

# Automatic tunning
system.time(modelo_c50_auto <- train(brand ~ ., 
                         data = trainSet, 
                         method = "C5.0",
                         tuneLength = 3,
                         trControl = ctrl,
                         metric = "ROC",
                         preProc = c("center", "scale")))
```

```{r}
modelo_c50_auto
```

ROC has been used as a criterium to select the best model since ours is a 2 class problem. ROC gives an indication of how well the clasification has resulted. The closer to 1 the value of ROC, the best clasified are the classes.

### Testing the model

After selecting the hyperparameters with cross-validation on the training set, the test set is used to assess the generalization error of the selected C5.0 model. 
Below the confusion matrix for the test set can be appreciated. An accuracy of 0.9248 and a kappa of 0.8402 speak for a very good prediction.

```{r}
predict_c50_auto_classes <- predict(modelo_c50_auto, newdata = testSet)
predict_c50_auto_prob <- predict(modelo_c50_auto, newdata = testSet, type = "prob")
confusionMatrix(data = predict_c50_auto_classes, testSet$brand)
```

## Random Forest

### Hyperparameter selection with cross-validation (manual tunning)

For the hyperparameter selection the R package caret with manual tunning has been used. Tunning has been done across parameter mtry = [1,2,3].
10-fold cross validation and 1 repetition has been used to limit computational time.

```{r}
rf_ctrl <- trainControl(method = "repeatedcv", 
                     repeats = 1,
                     classProbs = T,
                     summaryFunction = twoClassSummary)

rf_grid <- expand.grid(mtry=c(1,2,3))

system.time(modelo_rf_man <- train(brand ~ ., 
                                   data = trainSet, 
                                   method = "rf", 
                                   trControl = rf_ctrl, 
                                   tuneGrid= rf_grid,
                                   metric = "ROC",
                                   preProc = c("center", "scale")))

```

### Testing the model

As can be seen in the cofusion matrix of prediction on the test set using the random forest model selected in previous step, accuracy (0.75) and kappa (0.41) are much lower than the ones obtained with C5.0 and automatic hyperparameter tunning.

```{r}
predict_rf_man_classes <- predict(modelo_rf_man, newdata = testSet)
head(predict_rf_man_classes)
confusionMatrix(data = predict_rf_man_classes, testSet$brand)
postResample(predict_rf_man_classes, testSet$brand)
```

### Hyperparameter selection with cross-validation (automatic tunning)

Now the automatic grid search of caret package is used for the hyperparameter selection of random forest. Again model is validated with 10-fold cross-validation. 

```{r}
rf_ctrl <- trainControl(method = "repeatedcv", 
                        repeats = 1,
                        classProbs = T,
                        summaryFunction = twoClassSummary)

system.time(modelo_rf_auto <- train(brand ~ ., 
                                    data = trainSet, 
                                    method = "rf", 
                                    trControl = rf_ctrl, 
                                    tuneLength= 3,
                                    metric = "ROC",
                                    preProc = c("center", "scale")))
```

### Testing the model

The confusion matrix of the predicted brands for the random forest selected with automatic tunning is shown below. An accuracy of 0.9232 and a kappa of 0.8362 indicate a very similar espected error as with C5.0.

```{r}
predict_rf_auto_classes <- predict(modelo_rf_auto, newdata = testSet)
confusionMatrix(data = predict_rf_auto_classes, testSet$brand)
postResample(predict_rf_auto_classes, testSet$brand)
```



## Selecting the model

Considering the results above, models C5.0 and random forest, both with automatic tunning, are good models. However, model C5.0 will be selected for requiring considerably less computation time. The error metrics are:

- Accuracy: 0.9248 
- Kappa: 0.8402

```{r, echo=F}
# resamps <- resamples(list( C50= modelo_c50_auto, rf =                              modelo_rf_man))
# summary(resamps)

```

The selected model has been used to predict the customer's computer brand preference in the incomplete survey.
A sample of the result is shown below. The complete file is attached to this report.

```{r}
predict2 <- predict(modelo_c50_auto, SurveyIncomplete)
SurveyIncomplete$brand <- predict2
head(SurveyIncomplete)
summary(SurveyIncomplete)
```

As can be seen in the summary, 63% of customer of the incomplete survey prefer Sony (3174) and 41% prefer Acer (1826)

```{r}
#modelLookup("rf")
```


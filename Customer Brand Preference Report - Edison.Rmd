---
title: "Brand Preference Prediction Report"
author: "Edison Guevara"
date: "14/10/2019"
output: 
    prettydoc::html_pretty:
    theme: cayman
    highlight: github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = T, warning = F, message = F)
```

# Goal and Objectives

In order for the Sales Teams to decide with which brand of computers (Acer or Sony) to persue a deeper strategic relationship, a market research firm has been engaged to conduct a survey on Blackwell's existing customers.

One of the objectives of the survey is to identify computer's brand preferences among the customers.

A model is to be developed and tested in order to predict the customer's brand preference based on other demographis data of an incomplete survey. This will allow us at the same time to extrapolate the results of the survey to all the customers and persue specific marketing strategies.

# Excecutive Summary

The results of this report are not conclusive as to persue a strategic partnership with Sony or Acer.

A new survey with a different market research company is recommended in order to validate the first survey. 

By exploring the current data and looking at some plots, results not consired realist have been found:

- There is a very similar ammount of data points in the whole range and for all features. 

- In some ranges the clasification is absolute. For instance, in the range slaray < 40k and age < 55 100% of the customers prefer Sony.

- The overall share of brand is approximately 60/40 (Sony/Acer) and this is like this for all features (except of salary) and in all ranges. 

However, a model has been built on the available (reliable?) data and the brand preference has been predicted on the incomplete survey. The share of brands is (as expected) again around 60/40 being Sony the most popular.

## Next steps

- Hire a new market research firm in order to get more reliable data
- Do a pre-evaluation of the date to determine whether it looks real or not.
- Develop a new model on the more reliable data and based on the learnings from the present excercise.

# Data 

The data used to develop the model contains around 10.000 survey of customer's brand preference including other demographic features:

- Salary (yearly)
- Age
- Educational level
- Make of primary car
- Zipcode
- Credit available
- Computers' brand preference (Acer/Sony)

# Pre-processing the data

The data has been first reviewd and the attributes type have been changed to be suited for the analysis.

```{r, echo = FALSE}
# Loading reguired libraries
pacman::p_load(caret, tidyverse, readr, party, ggthemes, plotly, shiny, C50)
pacman::p_load(C50)
library(party)
library(party)
library(C50)
# Setting working directory
setwd("C:/Users/edison/Documents/Ubiqum/Data Analytics Course/Module II/Task2_revisited/")

```

```{r, echo=FALSE}
# Import data

CompleteResponses <- read.csv(file="Data/CompleteResponses.csv", header=TRUE, sep=";")

SurveyIncomplete <- read.csv(file="Data/SurveyIncomplete.csv", header=TRUE, sep=",")


# Changing attributes type
CompleteResponses$age <- as.integer(CompleteResponses$age)
CompleteResponses$elevel <- as.ordered(CompleteResponses$elevel)
CompleteResponses$car <- as.factor(CompleteResponses$car)
CompleteResponses$zipcode <- as.factor(CompleteResponses$zipcode)
CompleteResponses$brand <- as.character(CompleteResponses$brand)

# Changing names of levels in brand
CompleteResponses[which(CompleteResponses$brand == 0), 
                  "brand"] <- "Acer"
CompleteResponses[which(CompleteResponses$brand == 1), 
                  "brand"] <- "Sony"

CompleteResponses$brand <- as.factor(CompleteResponses$brand)

SurveyIncomplete$salary <- as.numeric(SurveyIncomplete$salary)
SurveyIncomplete$age <- as.integer(SurveyIncomplete$age)
SurveyIncomplete$elevel <- as.ordered(SurveyIncomplete$elevel)
SurveyIncomplete$car <- as.factor(SurveyIncomplete$car)
SurveyIncomplete$zipcode <- as.factor(SurveyIncomplete$zipcode)
SurveyIncomplete$credit <- as.numeric(SurveyIncomplete$credit)
SurveyIncomplete$brand <- as.factor(SurveyIncomplete$brand)

```

# Exploring the Data

Below the summary of the complete survey is shown:

```{r}
summary(CompleteResponses)
```


## Histograms
The distribution of the data has been studied using histograms. Below it can be seen different histograms for the original data, as well as histograms for the incomplete survey data. In this way we can compare the distribution among both samples (i.e. original data and incomplete data). The histograms have been segregated by brand, in order to look for associations at the same time.


```{r, echo=F}
# Histograms
# Hist salary
ggplot(CompleteResponses, aes(x = salary, fill = brand)) + 
  geom_histogram(binwidth = 10000, 
                 color = "white") + 
  ggtitle("Histogram CompleteResponse - Salary")
#  scale_fill_manual(values = c("grey", "black")) + 
#  facet_grid(elevel ~ zipcode, labeller = label_both) +
#  facet_grid(. ~ elevel, labeller = label_both)

ggplot(SurveyIncomplete, aes(x = salary)) + 
  geom_histogram(binwidth = 10000, 
                 color = "white") + 
  ggtitle("Histogram SurveyIncomplete - Salary")

```

The overall distribution of salary is similar in both data sets. This is very important in order to have a reliable model. 
On the other hand, it can be seen that the distribution of salary for Acer fans is different to the one of Sony fans. This revelas some dependancy between salary and brand preference.

```{r, echo=FALSE}
# Hist age
ggplot(CompleteResponses, aes(x = age, fill = brand)) + 
  geom_histogram(binwidth = 5, color = "white" ) + 
  ggtitle("Histogram CompleteResponse - age")
ggplot(SurveyIncomplete, aes(x = age)) + 
  geom_histogram(binwidth = 5, color = "white") + 
  ggtitle("Histogram SurveyIncomplete - age")
```

The overall distribution of age is also very similar among both datasets.
Unlike while looking at salary, in the case of age there is not clear association between the latest and the brand.

```{r, echo = F}
# Hist elevel
CompleteResponses$elevel <- as.integer(CompleteResponses$elevel)
SurveyIncomplete$elevel <- as.integer(SurveyIncomplete$elevel)

ggplot(CompleteResponses, aes(x = elevel, fill = brand)) + 
  geom_histogram(binwidth = 1, color = "white") + 
  ggtitle("Histogram CompleteResponse - education level")

ggplot(SurveyIncomplete, aes(x = elevel)) + 
  geom_histogram(binwidth = 1, color = "white") + 
  ggtitle("Histogram SurveyIncomplete - education level")

CompleteResponses$elevel <- as.ordered(CompleteResponses$elevel)
SurveyIncomplete$elevel <- as.ordered(SurveyIncomplete$elevel)
```

Key:

- 0	Less than High School Degree
- 1	High School Degree
- 2	Some College
- 3	4-Year College Degree
- 4	Master's, Doctoral or Professional Degree


```{r, echo=F}
# Hist car
CompleteResponses$car <- as.integer(CompleteResponses$car)
SurveyIncomplete$car <- as.integer(SurveyIncomplete$car)

ggplot(CompleteResponses, aes(x = car, fill = brand)) + 
  geom_histogram(binwidth = 1, color = "white") + 
  ggtitle("Histogram CompleteResponse - car")
ggplot(SurveyIncomplete, aes(x = car)) + 
  geom_histogram(binwidth = 1, color = "white") + 
  ggtitle("Histogram SurveyIncomplete - car")

CompleteResponses$car <- as.factor(CompleteResponses$car)
SurveyIncomplete$car <- as.factor(SurveyIncomplete$car)
```

Key:

- 1	BMW
- 2	Buick
- 3	Cadillac
- 4	Chevrolet
- 5	Chrysler
- 6	Dodge
- 7	Ford
- 8	Honda
- 9	Hyundai
- 10	Jeep
- 11	Kia
- 12	Lincoln
- 13	Mazda
- 14	Mercedes Benz
- 15	Mitsubishi
- 16	Nissan
- 17	Ram
- 18	Subaru
- 19	Toyota
- 20	None of the above


```{r, echo=F}
# Hist zipcode
CompleteResponses$zipcode <- as.integer(CompleteResponses$zipcode)
SurveyIncomplete$zipcode <- as.integer(SurveyIncomplete$zipcode)

ggplot(CompleteResponses, aes(x = zipcode, fill = brand)) + 
  geom_histogram(binwidth = 1, color = "white") + 
  ggtitle("Histogram CompleteResponse - zipcode")

ggplot(SurveyIncomplete, aes(x = zipcode)) + 
  geom_histogram(binwidth = 1, color = "white") + 
  ggtitle("Histogram SurveyIncomplete - zipcode")

CompleteResponses$zipcode <- as.factor(CompleteResponses$zipcode)
SurveyIncomplete$zipcode <- as.factor(SurveyIncomplete$zipcode)
```

0	New England
1	Mid-Atlantic
2	East North Central
3	West North Central
4	South Atlantic
5	East South Central
6	West South Central
7	Mountain
8	Pacific

```{r, echo=F}
# Hist credit
ggplot(CompleteResponses, aes(x = credit, fill = brand)) + 
  geom_histogram(binwidth = 50000, color = "white") + 
  ggtitle("Histogram CompleteResponse - credit")
ggplot(SurveyIncomplete, aes(x = credit)) + 
  geom_histogram(binwidth = 50000, color = "white") + 
  ggtitle("Histogram SurveyIncomplete - credit")

```

The distributions of education level, car, zipcode and credit are pretty similar in both datasets. As explained before, this is very important in order to have a reliable model.

## Scatter plots

In order to explore deeper the relationship between the different attributes and brand, scatter plots have been made.

```{r, echo=F}
ggplot(CompleteResponses, aes(x = age, y = salary, color = brand)) +
  geom_point() + geom_smooth()

```

```{r, echo=F}
ggplot(CompleteResponses, aes(x = elevel, y = salary, color = brand)) + geom_point(position = "jitter")

```

As can be seen in plot salary vs age, there is also a dependancy of brand towards attribute age. 
On the other hand, there seems not to be any association with education level and brand.

## Looking for outliers

Boxplots for the numerical attributes (salary and credit) have been obtained. As can be seen there are no outliers in either one variable.

```{r, echo=F}
ggplot(CompleteResponses, aes(x = brand, y = salary, 
                              fill = brand)) + 
  geom_boxplot() + 
  stat_summary(fun.y = median, color = "white", geom = "text",
               vjust = -0.7, 
               aes(label = round(..y.., digits = 1)))
```

```{r, echo=F}
ggplot(CompleteResponses, aes(x = brand, y = credit, 
                              fill = brand)) + 
  geom_boxplot() + 
  stat_summary(fun.y = median, color = "white", geom = "text",
               vjust = -0.7, 
               aes(label = round(..y.., digits = 1)))
```

# Feature selection

A single Decision Tree has been obtained in order to select the attributes which have an association to the investigated veriable, brand.

As can be seen in the Decision Tree below, only salary and age play a considerable role.

However, all attributes will be used for the development of the models, since both models used in this study are decision-tree-based and the unimportant attributes will be anyways discarded.

```{r, echo=F}
set.seed(123)
DecisionTree_brand <- ctree(brand ~ ., data = CompleteResponses, controls = ctree_control(maxdepth = 3))
plot(DecisionTree_brand)
```

# Modeling

Two different decision tree classification methods have been included: C5.0 and RandomForest.

##  Creating training and testing sets

In order to train and test the models, the original data (complete data) has been split into a training and a test set. The proportion used is 0.75 to 0.25.

```{r}
trainSize <- createDataPartition(y=CompleteResponses$brand, p = .75, list = F)
trainSet <- CompleteResponses[trainSize,]
testSet <- CompleteResponses[-trainSize,]
```

## C5.0

### Training the model

The C5.0 model has been trained using cross-validation 10 folds, 3 repetitions, as resampling method.
Below it can be seen the results using automatic tuning with tunelength = 2.

```{r, echo=F}
ctrl <- trainControl(method = "repeatedcv", 
                     repeats = 3,
                     classProbs = T,
                     summaryFunction = twoClassSummary)

# Automatic tunning
modelo_c50_auto <- train(brand ~ ., 
                data = trainSet, 
                method = "C5.0",
                tuneLength = 2,
                trControl = ctrl,
                metric = "ROC",
                preProc = c("center", "scale"))
```

```{r}
modelo_c50_auto
```

ROC has been used as a criterium to select the best model since ours is a 2 class problem. ROC gives an indication of hoe well the clasification has resulted. The closer to 1 the value of ROC, the best clasified are the classes.

### Testing the model

After training the C5.0 model on the training set, its performance has been tested on the test set.
Below the confusion matrix for the test set can be appreciated. An accuracy of 0.9276 and a kappa of 0.8486 speak for a very good prediction.

```{r}
predict_c50_auto_classes <- predict(modelo_c50_auto, newdata = testSet)
predict_c50_auto_prob <- predict(modelo_c50_auto, newdata = testSet, type = "prob")
confusionMatrix(data = predict_c50_auto_classes, testSet$brand)
```

## Random Forest

### Training the model

The model Random Forest has been trained using the R package "caret". The manual tunning option has been used for the model to iterate in paramter mtry with values 1, 2 and 3. 
10-fold cross validation and 1 repetition has been used to limit computational times.

```{r}
rf_ctrl <- trainControl(method = "repeatedcv", 
                     repeats = 1,
                     classProbs = T,
                     summaryFunction = twoClassSummary)

rf_grid <- expand.grid(mtry=c(1,2,3))

system.time(modelo_rf_man <- train(brand ~ ., 
                                   data = trainSet, 
                                   method = "rf", 
                                   trControl = rf_ctrl, 
                                   tuneGrid= rf_grid,
                                   metric = "ROC",
                                   preProc = c("center", "scale")))

```

## Testing the model

As can be seen in the cofusion matrix of the random forest model applied on the test set, accuracy (0.732) and kappa (0.3654) are much lower than the ones obtained with C5.0.

```{r}
predict_rf_man_classes <- predict(modelo_rf_man, newdata = testSet)
head(predict_rf_man_classes)
confusionMatrix(data = predict_rf_man_classes, testSet$brand)
```

## Selecting the model

Considering the results above, model C5.0 with automatic tunning has been selected to be the most optimal. The error metrics are:

- Accuracy: 0.9276
- Kappa: 0.8486

```{r, echo=F}
# resamps <- resamples(list( C50= modelo_c50_auto, rf =                              modelo_rf_man))
# summary(resamps)

```

The selected model has been used to predict the customer's computer brand preference in the incomplete survey.
A sample of the result is shown below. The complete file is attached to this report.

```{r}
predict2 <- predict(modelo_c50_auto, SurveyIncomplete)
SurveyIncomplete$brand <- predict2
head(SurveyIncomplete)
summary(SurveyIncomplete)
```

As can be seen in the summary, 59% of customer of the incomplete survey prefer Sony (2950) and 41% prefer Acer (2050)